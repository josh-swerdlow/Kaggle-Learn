{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "415462fd74327422e947bdeacb9410ad61dd947f"
   },
   "source": [
    "# BigQuery\n",
    "\n",
    "**NOTE**: None of the datasets are found in this repository. They're large and I didn't feel like taking them from Kaggle's website just to be able to run the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bq_helper\n",
    "# create a helper object for our bigquery dataset\n",
    "chicago_crime = bq_helper.BigQueryHelper(active_project= \"bigquery-public-data\", \n",
    "                                       dataset_name = \"chicago_crime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f248824acf044cc09732f56df442bad6865c05bd"
   },
   "source": [
    "## Get a list of the tables in the BigQuery Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chicago_crime.list_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4094e27dec0601310f4915fea95b6736ec81782d"
   },
   "source": [
    "## Look at one tables schema and check out the head\n",
    "\n",
    "The columns represent (from left to right):\n",
    "- The name of the column\n",
    "- The datatype of the column\n",
    "- The mode of the column (NULLABLE means that a column allows NULL values, and is the default)\n",
    "- A description of the data in that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe96721cf6e3d3d3f5962f50f4ab0b47b30b9412",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chicago_crime.table_schema(\"crime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1afdcf59b039322e0ddda65f213b4413d19a687c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chicago_crime.head(\"crime\", selected_columns=[\"date\", \"description\", \"arrest\"], num_rows=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2a9591ea83668e1ba710171ced488c9ce88b99f6"
   },
   "source": [
    "## Check the size of an SQL query before executing it!\n",
    "\n",
    "This can be important because, in large datasets, scanning a lot of data can be very costly. For example, Kaggle let's users scan 5 TB of data every 30 days.\n",
    "\n",
    "__NOTE__: I have no idea what estimate_query_size returns and I can't find documentation for bq_helper. From context clues of the lesson I think the value returned is in units of GBs. Also, this returns the estimated size of the data returned from the query. It does not tell you **anything** about the amount of the data that must be scanned.\n",
    "\n",
    "### Running the Query\n",
    "- *BigQueryHelper.query_to_pandas(query)*: This method takes a query and returns a Pandas dataframe.\n",
    "- *BigQueryHelper.query_to_pandas_safe(query, max_gb_scanned=1)*: This method takes a query and returns a Pandas dataframe only if the size of the query is less than the upperSizeLimit (1 gigabyte by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "df3da50906e86dca99dd1681066ad8b6964af2db",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This query looks at the crime table of the Chicago crime data set\n",
    "# It scans for all descriptions where arrest is False\n",
    "query = \"\"\"SELECT description\n",
    "            FROM `bigquery-public-data.chicago_crime.crime`\n",
    "            WHERE arrest = False\n",
    "        \"\"\"\n",
    "chicago_crime.estimate_query_size(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46419cb85de88131f85baac8e9210c5535aae23f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arrested_descriptions = chicago_crime.query_to_pandas_safe(query, max_gb_scanned=0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80ac73c560790b66aedbeeb7258c38908e0da244",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arrested_descriptions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "210f9b5170d5bb03aa691bcffd16306b0d93db34"
   },
   "source": [
    "# SQL Queries: Select, From, Where\n",
    "\n",
    "This will following along with the SQL exercise provided in the lessons using the openaq dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "109b44a249a4250efa7aa85fe1d3cf3d384152d9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bq_helper\n",
    "# create a helper object for this dataset\n",
    "open_aq = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",\n",
    "                                   dataset_name=\"openaq\")\n",
    "\n",
    "# print all the tables in this dataset (there's only one!)\n",
    "open_aq.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3284939d43cde02bddab10857ff380b4af2dc06f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "open_aq.table_schema(\"global_air_quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "735a6eab7fca0bcd93c0c25983d8aa06ed91a589",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "open_aq.head(\"global_air_quality\", selected_columns=\"unit\", num_rows=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "563f2578b9fc45ed102c851af99a9328f63f65c3"
   },
   "source": [
    "## Question 1: Which counties use a unit other than ppm to measure any type of pullution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "691893f3ecefdce6768ebb92457e141aea1e9be6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\" SELECT country\n",
    "            FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "            WHERE unit != \"ppm\"\n",
    "        \"\"\"\n",
    "\n",
    "non_ppm_countries = open_aq.query_to_pandas_safe(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "045327b79dbaf3ccb6c3596ad8bc9096d310b54e"
   },
   "source": [
    "The countries with the most measurements not using ppm as a unit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d3e994597dfda1b364515f9d34e289a9d9c02b67",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_ppm_countries.country.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8c33d5ee2b82aaecb7cabdd74705a01121f59f4"
   },
   "source": [
    "## Question 2: Which pollutants have a value of exactly 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b785b12a85aec7dbcb51214e334738849ac57d97",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT pollutant\n",
    "            FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "            WHERE value = 0\n",
    "        \"\"\"\n",
    "\n",
    "zero_value_pollutants = open_aq.query_to_pandas_safe(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "972bf9ab244634fb5252919acba325506dba4e51"
   },
   "source": [
    "All pollutants with 0 value counts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c955a0a360145f5832146680239da8c02584888a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_value_pollutants.pollutant.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f87f0205ea58477874587079867d1603b929a757"
   },
   "source": [
    "# SQL Queries: Group By, Having, and Count\n",
    "\n",
    "- **COUNT**: Returns the number of entries given the name of a column (i.e. COUNT(name) will return the number of entries for the column 'name')\n",
    "    - *Note*: Count is an example of an **aggregate function** which a type of SQL function that takes in many values and returns one (i.e. SUM() or AVERAGE())\n",
    "- **GROUP BY**: GROUP BY takes the name of one or more column and tells SQL that we want to treat rows that have the same value in that column as a single group when we apply aggregate functions like COUNT().\n",
    "- **GROUP BY ... HAVING**: This is the same as GROUP BY, but it enforces a criteria on the groups and only returns groups that meet the criteria.\n",
    "\n",
    "These exercises will use the hacker news data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37eeda834628533199e5a75e747ba3eafc15b6cc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bq_helper\n",
    "\n",
    "hacker_news = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\", dataset_name=\"hacker_news\")\n",
    "\n",
    "hacker_news.list_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "39763db103903912a87d0cd85effea76f219438f"
   },
   "source": [
    "## Question 1: How many stories are there of each type in the full table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3e473e115a04d988d3aa549420bc42c926e723c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hacker_news.table_schema(\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5383b1bb4920c262c7fa3a228eb2a647ed78666f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT type, COUNT(id)\n",
    "            FROM `bigquery-public-data.hacker_news.full`\n",
    "            GROUP BY type\n",
    "        \"\"\"\n",
    "\n",
    "unique_stories = hacker_news.query_to_pandas_safe(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4ca417fac4d7c70e26ee1510363317be627635a2"
   },
   "source": [
    "The number of stories for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eab96f3a3a49b050c4312067967ac52815dd259d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_stories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9b3e0f6463769e03d1b91899f5b43b8100093426"
   },
   "source": [
    "## Question 2: How many comments have been deleted? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "02059e9b092ff54c92096fb86e0cb124a8ff2fff",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hacker_news.table_schema(\"comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f312d6feb9ca9de85b511eac1f6fd058791fbe2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT deleted, COUNT(ID)\n",
    "            FROM `bigquery-public-data.hacker_news.comments`\n",
    "            GROUP BY deleted\n",
    "            HAVING deleted = True\n",
    "        \"\"\"\n",
    "\n",
    "deleted_comments = hacker_news.query_to_pandas_safe(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "76ddd6c54bc2e96069327a01531903eff81b8e25"
   },
   "source": [
    "The number of deleted comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "95680cf63edb3b65ed08a1ce4bc99af775b37531",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deleted_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "65527023f132970622eab9d8f5838939be6fda38"
   },
   "source": [
    "# SQL Queries: Order By and Extract\n",
    "\n",
    "Order by is typically the last clause one will add into their SQL query because you'll use it to sort the results returned by the rest of the query.\n",
    "\n",
    "- **Numerical Data**: By default, the column will return the data sorted in lowest to highest. \n",
    "- **String Data**: By default, the column will be sorted alphabetically from a-z.\n",
    "\n",
    "If the **DESC** keyword is specified (i.e. ORDER BY *column_name* DESC) then it will reverse the sort order (i.e. high-low, z-a).\n",
    "\n",
    "### Dates\n",
    "\n",
    "Dates can be stored in BigQuery using *DATA* or *DATETIME* format.\n",
    "- *Date* Format: Year first, month, then day\n",
    "> `YYYY-[M]M-[D]D`\n",
    "> - YYYY: Four-digit year\n",
    "> - [M]M: One or two digit month\n",
    "> - [D]D: One or two digit day\n",
    "- *DATETIME/TIMESTAMP* Format: Same as *Date* Format, but the time information is appended\n",
    "> `YYYY-[M]M-[D]D[( |T)[H]H:[M]M:[S]S[.DDDDDD]][time zone]`\n",
    "> - YYYY: Four-digit year\n",
    "> - [M]M: One or two digit month\n",
    "> - [D]D: One or two digit day\n",
    "> - ( |T): A space or a T separator\n",
    "> - [H]H: One or two digit hour (valid values from 00 to 23)\n",
    "> - [M]M: One or two digit minutes (valid values from 00 to 59)\n",
    "> - [S]S: One or two digit seconds (valid values from 00 to 59)\n",
    "> - [.DDDDDD]: Up to six fractional digits (i.e. up to microsecond precision)\n",
    "> - (TIMESTAMP only) [time zone]: String representing the time zone\n",
    "\n",
    "Often times, one will only want to look at certain parts of the date (i.e. the year or the day). This can be accomplished using the EXTRACT function as follows:\n",
    "\n",
    "```\n",
    "SELECT EXTRACT(DAY FROM column_with_timestamp)\n",
    "FROM `bigquery....\n",
    "```\n",
    "This query will return one column with the day from each date in the column.\n",
    "\n",
    "```\n",
    "SELECT EXTRACT(WEEK FROM column_with_timestamp)\n",
    "FROM `bigquery...`\n",
    "```\n",
    "This query will return one column with the week (1-53) from each date in the column.\n",
    "\n",
    "SQL is really and we can perform advance temporal extractions from dates, for more [see all the functions](https://cloud.google.com/bigquery/docs/reference/legacy-sql) one can use with date in BigQuery under \"Data and time functions\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "900bc45def47daad0b2a4ea9675ca1c18753388b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import package with helper functions \n",
    "import bq_helper\n",
    "\n",
    "# create a helper object for this dataset\n",
    "accidents = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",\n",
    "                                   dataset_name=\"nhtsa_traffic_fatalities\")\n",
    "\n",
    "accidents.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b73e9ea84d05d0327c8290e313b2eb316dbd7981",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accidents.table_schema(\"accident_2015\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1632ee33768de6512ebd6bff68dcf67ff34df00c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accidents.head(\"accident_2015\", selected_columns=\"number_of_drunk_drivers\", num_rows=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0ca5e07e4d8b6a491fbf421c60e4430fa92ece06"
   },
   "source": [
    "## Question 1: Which hours of the day do the most accidents occur during?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "19e39e53c2cf10840ae5a087abcee11d85f24f50",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will get the number of accidents by counting the consecutive number column\n",
    "# We will get the hour of the day with the EXTRACT function\n",
    "# We want to group by hour of the day to aggregate the number of accidents at each hour\n",
    "# and then order them in high-low order\n",
    "query = \"\"\"SELECT COUNT(consecutive_number), EXTRACT(HOUR FROM timestamp_of_crash)\n",
    "            FROM `bigquery-public-data.nhtsa_traffic_fatalities.accident_2015`\n",
    "            GROUP BY EXTRACT(HOUR FROM timestamp_of_crash)\n",
    "            ORDER BY COUNT(consecutive_number) DESC\n",
    "        \"\"\"\n",
    "\n",
    "most_accidents_hourly = accidents.query_to_pandas_safe(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "54aafd17225c61b7ec72becbf84ae4e234970fda",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_accidents_hourly\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(most_accidents_hourly.f1_, most_accidents_hourly.f0_)\n",
    "plt.title(\"Aggregate Hourly Accidents in the US in 2015\")\n",
    "plt.xlabel(\"Hour of the Day 0-23\")\n",
    "plt.ylabel(\"Number of Accidents\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "501999bf050bf4f4a86b7907dc7b411ef0ad33f6"
   },
   "source": [
    "## Question 2: Which state has the most drunk drivers?\n",
    "*Note: This is not the actual question in the lesson, it was original 'Which state has the most hit and run accidents?', but upon investigation the 'hit_and_run' column seems to have been removed from the dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6689b718d75b51c8da8c160e85dfad54b3db116d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will SELECT the number of drunk drivers by counting the number of drunk drivers column\n",
    "# We will SELECT the state name\n",
    "# We want to GROUP BY the state name to aggregate the number of drunk drivers per state\n",
    "# and then ORDER BY high-low order\n",
    "query = \"\"\"SELECT COUNT(number_of_drunk_drivers), state_name\n",
    "            FROM `bigquery-public-data.nhtsa_traffic_fatalities.accident_2015`\n",
    "            GROUP BY state_name\n",
    "            ORDER BY COUNT(number_of_drunk_drivers) DESC\n",
    "        \"\"\"\n",
    "\n",
    "drunk_drivers_per_state = accidents.query_to_pandas_safe(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a1a9c43c76d6b87f7ed33031cc9cd1faf58bd69b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "state_names = drunk_drivers_per_state.state_name\n",
    "state_numbs = [numb for numb, name in enumerate(state_names)]\n",
    "\n",
    "plt.scatter(state_numbs, drunk_drivers_per_state.f0_)\n",
    "plt.title(\"Drunk Drivers per State in 2015\")\n",
    "plt.xlabel(\"State\")\n",
    "plt.xticks(state_numbs, state_names, rotation='vertical', fontsize=9)\n",
    "plt.ylabel(\"Number of Drunk Drivers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c36c20658fd50e908e931f4bb4e7b5813bcfd3e2"
   },
   "source": [
    "## SQL Queries: AS and WITH\n",
    "\n",
    "AS pretty much allows you to alias columns to new names. See examples below\n",
    "```\n",
    "    SELECT EXTRACT(DAY FROM column_with_timestamp), data_point_3\n",
    "    FROM `bigquery-public-data.imaginary_dataset.imaginary_table`\n",
    "```\n",
    "```\n",
    "    SELECT EXTRACT(DAY FROM column_with_timestamp) AS day,\n",
    "            data_point_3 AS data\n",
    "    FROM `bigquery-public-data.imaginary_dataset.imaginary_table`\n",
    "```\n",
    "    \n",
    "Not only does this allow the user to continue using the alias within the query, but it also with rename the resulting columns in the datastructure that is returned from the scan (i.e. the DateFrame).\n",
    "\n",
    "### Common Table Expressions (CTEs)\n",
    "\n",
    "One can combine the powerful AS clause with the WITH clause to create WITH...AS clauses. These can then be used to create a CTE.\n",
    "> **Common table expression**: A temporary table that you return within your query. You can then write queries against the new table you've created. \n",
    "> CTE's only exist inside the query where you create them, though, so you can't reference them in later queries.\n",
    "\n",
    "The following exercises will use the bitcoin dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45bdd17efd4ded816643fa11717c010f6e4423ea",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import package with helper functions \n",
    "import bq_helper\n",
    "\n",
    "# create a helper object for this dataset\n",
    "bitcoin_blockchain = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",\n",
    "                                              dataset_name=\"bitcoin_blockchain\")\n",
    "\n",
    "bitcoin_blockchain.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cc13100226107879f00cf3513433e5704fb09823",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bitcoin_blockchain.table_schema(\"transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2dc6858242e80a3b9247c4c58eb091e1b1989b2b"
   },
   "source": [
    "## Question 1: How many Bitcoin transactions were made each day in 2017?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1b4a00d91df8071c17890647dc30dbddfbf34fed",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, make a CTE with the timestamp in DATETIME format, and the transaction_id\n",
    "# Then, COUNT the transaction_ids, and create a column for days and years\n",
    "# Group the data by year such that year must be 2017\n",
    "query = \"\"\"WITH time AS\n",
    "            (\n",
    "                SELECT TIMESTAMP_MILLIS(timestamp) AS trans_time, transaction_id\n",
    "                FROM `bigquery-public-data.bitcoin_blockchain.transactions`\n",
    "            )\n",
    "            SELECT COUNT(transaction_id) AS transactions, EXTRACT(DAYOFYEAR FROM trans_time) AS abs_day\n",
    "            FROM time\n",
    "            WHERE EXTRACT(YEAR FROM trans_time) = 2017\n",
    "            GROUP BY abs_day\n",
    "            ORDER BY abs_day            \n",
    "        \"\"\"\n",
    "\n",
    "daily_transactions_2017 = bitcoin_blockchain.query_to_pandas_safe(query, max_gb_scanned=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a1db8a8d85bf1c5fffa7886202f63457717700b4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(daily_transactions_2017.abs_day, daily_transactions_2017.transactions)\n",
    "plt.title(\"Daily BitCoin Transactions in 2017\")\n",
    "plt.ylabel(\"Number of Transactions\")\n",
    "plt.xlabel(\"Day in the Year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c4f40d410cf8d565286d5273476173b5ed9cbbe"
   },
   "source": [
    "## Question 2: How many transactions are associated with each merkle root?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ac02ee17831e075fd5cf73cf6bba0345dcdc2b3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "            SELECT COUNT(transaction_id) AS transactions, merkle_root AS root\n",
    "            FROM `bigquery-public-data.bitcoin_blockchain.transactions`\n",
    "            GROUP BY root            \n",
    "        \"\"\"\n",
    "\n",
    "transactions_p_mrklRoot = bitcoin_blockchain.query_to_pandas_safe(query, max_gb_scanned=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6ea62fa039602c0435e3ebb1d1a820b4544342c0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transactions_p_mrklRoot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3815fcc2c8960a512e9ada74b8b210b6afd02341"
   },
   "source": [
    "## SQL Queries: JOIN\n",
    "\n",
    "The JOIN clauses is used to combine multiple tables in some way. JOIN represents a large group of clauses depending on how the user would like to JOIN things. For example, the INNER JOIN clause combines only if the element of the column is found in both tables.\n",
    "\n",
    "## Question 1: How many commits (recorded in the \"sample_commits\" table) have been made in repos written in the Python programming language? (I'm looking for the number of commits per repo for all the repos written in Python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6983b542f967ee4d5e06c5aa0035b74520b1c7dd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import package with helper functions \n",
    "import bq_helper\n",
    "\n",
    "# create a helper object for this dataset\n",
    "github = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",\n",
    "                                              dataset_name=\"github_repos\")\n",
    "\n",
    "github.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82bd541149c60bc3d3d614bc769aba88a7d2baa1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Table to find commits\n",
    "github.table_schema(\"sample_commits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1a161cbf978073eb42a9243a0a54f465a982c69d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Table to get repos (repo_name) and file names (path)\n",
    "github.table_schema(\"sample_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5a0891f7109bec3f5a00208ffbd1d45fde120472",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "github.head(\"sample_files\", selected_columns=[\"repo_name\", \"path\"], num_rows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51fcc5892f8686a163fc47f04e46af89f256d026",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# JOIN the two tables on the repo_name\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT sf.repo_name, COUNT(sc.commit) AS numb_commits\n",
    "        FROM `bigquery-public-data.github_repos.sample_files` AS sf\n",
    "        INNER JOIN `bigquery-public-data.github_repos.sample_commits` AS sc ON sf.repo_name = sc.repo_name\n",
    "        WHERE sf.path LIKE '%.py'\n",
    "        GROUP BY sf.repo_name\n",
    "        ORDER BY numb_commits DESC\n",
    "\"\"\"\n",
    "\n",
    "repos = github.query_to_pandas_safe(query, max_gb_scanned=5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86432188ba895f9042b612d7065a8ab53bf3658c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f40aaf7f7cabc0c1db224b24d00deb52e1b3d267"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
